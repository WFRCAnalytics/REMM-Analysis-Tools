{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "from arcpy import env\n",
    "import os\n",
    "import numpy as np\n",
    "from arcgis import GIS\n",
    "from arcgis.features import GeoAccessor\n",
    "from arcgis.features import GeoSeriesAccessor\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.parallelProcessingFactor = \"90%\"\n",
    "\n",
    "# show all columns\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "# pd.DataFrame.spatial.from_featureclass(???)  \n",
    "# df.spatial.to_featureclass(location=???,sanitize_columns=False)  \n",
    "\n",
    "# gsa = arcgis.features.GeoSeriesAccessor(df['SHAPE'])  \n",
    "# df['AREA'] = gsa.area  # KNOW YOUR UNITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NA values in Spatially enabled dataframes (ignores SHAPE column)\n",
    "def fill_na_sedf(df_with_shape_column, fill_value=0):\n",
    "    if 'SHAPE' in list(df_with_shape_column.columns):\n",
    "        df = df_with_shape_column.copy()\n",
    "        shape_column = df['SHAPE'].copy()\n",
    "        del df['SHAPE']\n",
    "        return df.fillna(fill_value).merge(shape_column,left_index=True, right_index=True, how='inner')\n",
    "    else:\n",
    "        raise Exception(\"Dataframe does not include 'SHAPE' column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = r'.\\\\Outputs\\progession_metrics_average'\n",
    "if not os.path.exists(outputs):\n",
    "    os.makedirs(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parcel Equivalency Table\n",
    "eq = pd.read_csv(r\".\\Inputs\\parcel_eq_v5.csv\")\n",
    "centers_eq_ids = eq[eq['CENTER_NAME'].isna() == False]['parcel_id'].to_list()\n",
    "\n",
    "# centers shape\n",
    "centers_sdf = pd.DataFrame.spatial.from_featureclass(r\".\\Inputs\\WC_2050_Centers.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "remm_folder_1 = r'E:\\Projects\\REMM2_For_Python3_Internal_Use'\n",
    "remm_folder_2 = r'E:\\Projects\\REMM2_For_Python3_Internal_Use'\n",
    "remm_folder_3 = r'E:\\Projects\\REMM2_For_Python3_Internal_Use'\n",
    "remm_folder_4 = r'E:\\Projects\\REMM2_For_Python3_Internal_Use'\n",
    "remm_folder_5 = r'E:\\Projects\\REMM2_For_Python3_Internal_Use'\n",
    "remm_folder_6 = r'E:\\Projects\\REMM2_For_Python3_Internal_Use'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "remm_folders = [remm_folder_1, remm_folder_2, remm_folder_3, remm_folder_4, remm_folder_5, remm_folder_6]\n",
    "remm_progression_folders = [os.path.join(x, 'REMMRun\\Progression_Metrics') for x in remm_folders]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_ignore_base(path, year):\n",
    "    csvs = glob.glob(os.path.join(path, f'run_*_year_{year}_parcel_progression_metrics.csv'))\n",
    "    csvs = [csv for csv in csvs if 'base'not in csv]\n",
    "    if len(csvs) > 1:\n",
    "        print('warning multiple tables were globbed; only the first will be returned')\n",
    "    return pd.read_csv(csvs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df(df, year):\n",
    "    df = df.set_index('parcel_id')\n",
    "    df.loc[(df['is_sf']==1), 'sf_units'] = df['residential_units']\n",
    "    df.loc[(df['is_mf']==1), 'mf_units'] = df['residential_units']\n",
    "    df['industrial_jobs'] = df['jobs_wholesale'] + df['jobs_manuf']\n",
    "    df['retail_jobs'] = df['jobs_retail'] + df['jobs_accom_food']\n",
    "    df['office_jobs'] = df['jobs_office'] + df['jobs_gov_edu'] + df['jobs_health'] + df['jobs_other']\n",
    "    df.loc[(df['has_buildings'] != 1), 'vacant_acres'] = df['parcel_acres']\n",
    "    df.loc[(df['has_buildings'] != 1) & (df['developable'] == 1), 'vacant_devacres'] = df['parcel_acres']\n",
    "    df['vacant_acres'].fillna(0, inplace=True)\n",
    "    df['vacant_devacres'].fillna(0, inplace=True)\n",
    "    df['households'] = df['households_count']\n",
    "    df = df[['sf_units', 'mf_units', 'households', 'job_spaces', 'industrial_jobs', 'retail_jobs', 'office_jobs', 'vacant_acres', 'vacant_devacres']].copy()\n",
    "    return df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n",
      "warning multiple tables were globbed; only the first will be returned\n"
     ]
    }
   ],
   "source": [
    "# base = centers_sdf[['CenterName', 'DEVACRES', 'SHAPE']].copy()\n",
    "for year in range(2019,2050):\n",
    "    dfs_current_year = [get_table_ignore_base(f, year) for f in remm_progression_folders]\n",
    "    dfs_processed = [prepare_df(df, year) for df in dfs_current_year] \n",
    "\n",
    "    # stack average the 6 runs together\n",
    "    data_stack = pd.concat(dfs_processed)\n",
    "    average = data_stack.groupby(data_stack.index).mean().reset_index().round().astype(int)\n",
    "    average['residential_units'] = average['sf_units'] + average['mf_units']\n",
    "    average['total_jobs'] = average['office_jobs'] + average['retail_jobs'] + average['industrial_jobs']\n",
    "    average.to_pickle(os.path.join(outputs, f'averaged_parcel_progression_metrics_{year}.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parcel_id</th>\n",
       "      <th>sf_units</th>\n",
       "      <th>mf_units</th>\n",
       "      <th>households</th>\n",
       "      <th>job_spaces</th>\n",
       "      <th>industrial_jobs</th>\n",
       "      <th>retail_jobs</th>\n",
       "      <th>office_jobs</th>\n",
       "      <th>vacant_acres</th>\n",
       "      <th>vacant_devacres</th>\n",
       "      <th>residential_units</th>\n",
       "      <th>total_jobs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1122</td>\n",
       "      <td>1</td>\n",
       "      <td>409</td>\n",
       "      <td>712</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   parcel_id  sf_units  mf_units  households  job_spaces  industrial_jobs  \\\n",
       "0          1         0         0           0           0                0   \n",
       "1          2         0         0           0        1122                1   \n",
       "2          3         0         0           0           7                4   \n",
       "3          4         0         0           0          14                5   \n",
       "4          5         0         0           0          28               22   \n",
       "\n",
       "   retail_jobs  office_jobs  vacant_acres  vacant_devacres  residential_units  \\\n",
       "0            0            0             0                0                  0   \n",
       "1          409          712             0                0                  0   \n",
       "2            0            2             0                0                  0   \n",
       "3            3            6             0                0                  0   \n",
       "4            0            6             0                0                  0   \n",
       "\n",
       "   total_jobs  \n",
       "0           0  \n",
       "1        1122  \n",
       "2           6  \n",
       "3          14  \n",
       "4          28  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "unpickled_df = pd.read_pickle(r\".\\Outputs\\progession_metrics_average\\averaged_parcel_progression_metrics_2035.pkl\")\n",
    "unpickled_df.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3245673af07dcc28bdd829afb187282e9288a1f8195a5928b70ecba6e5973721"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
